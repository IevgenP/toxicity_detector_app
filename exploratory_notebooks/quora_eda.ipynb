{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'definitions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-743d46cc166f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdefinitions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROOT_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'definitions'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import collections\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from definitions import ROOT_DIR\n",
    "nltk.download('punkt')\n",
    "\n",
    "import string\n",
    "from src.preprocessing.custom_transformers import PunctuationRemover, StopWordsRemover, IntoLowerCase, ShortToLong\n",
    "from src.visualizers.visualiers import get_stats, plot_counter, count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Quora database\n",
    "q_df = pd.read_csv(ROOT_DIR+'/raw_data/quora_dataset.csv')\n",
    "print(q_df.loc[q_df['target']==1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dataset specific symbols to common ones\n",
    "q_df['question_text'] = q_df['question_text'].str.replace(\"â€™\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target value distribution\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot(x='target', data=q_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with number of words\n",
    "q_df['num_words'] = q_df['question_text'].apply(\n",
    "    lambda x: len([token for token in x.split(\" \") if token != \"\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for number of words\n",
    "print(\"Stats for whole dataset:\")\n",
    "get_stats(q_df, 'words', 'num_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One word as a question? It is interesting to look into.\n",
    "q_df.loc[q_df['num_words']==1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all one question are considered as trolling. This is a questionable approach of those who labeled the data. But for this specific case I will agree with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for number of words if target value is 0\n",
    "q_df_0 = q_df.copy().loc[q_df['target']==0, ]\n",
    "print(\"Stats for 0 target values:\")\n",
    "get_stats(q_df_0, 'words', 'num_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for number of words if target value is 1\n",
    "q_df_1 = q_df.copy().loc[q_df['target']==1, ]\n",
    "print(\"Stats for 0 target values:\")\n",
    "get_stats(q_df_1, 'words', 'num_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like authors of troll questions are too busy to type more than 64 words.vAlso distribution of number of words shows spikes with some ordered pattern. My suggestion is that trolling questions were automatically created (either for pupose of this competition or by Quora's trolls, when they posted questions). The conclusion from this section of analysis: max of 40 words is enough for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stop words from nltk library\n",
    "nltk.download('stopwords')\n",
    "eng_stop_words = nltk.corpus.stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for text transformations\n",
    "q_df['prep_text'] = q_df['question_text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('contracted', ShortToLong(['prep_text'])),\n",
    "        ('punctuation', PunctuationRemover(['prep_text'])),\n",
    "        ('lowercase', IntoLowerCase(['prep_text'])),\n",
    "        ('stopwords', StopWordsRemover(['prep_text'], eng_stop_words))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset using created pipeline\n",
    "pipeline.fit_transform(q_df)\n",
    "q_df.to_csv(ROOT_DIR + '/temp_data/quora_df_no_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unigrams frequency for whole dataset\n",
    "count_words(q_df, 'prep_text', 'unigrams', 15, ' for whole dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count bigrams frequency for whole dataset\n",
    "count_words(q_df, 'prep_text', 'bigrams', 15, ' for whole dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for sinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 0, ], 'prep_text', 'unigrams', 15, ' for sinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for sinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 0, ], 'prep_text', 'bigrams', 15, ' for sinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for sinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 0, ], 'prep_text', 'trigrams', 15, ' for sinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for insinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 1, ], 'prep_text', 'unigrams', 15, ' for insinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for insinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 1, ], 'prep_text', 'bigrams', 15, ' for insinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words frequency for insinsere questions only\n",
    "count_words(q_df.loc[q_df['target'] == 1, ], 'prep_text', 'trigrams', 15, ' for insinsere questions only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxicity",
   "language": "python",
   "name": "toxicity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
